{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "from result_analysis.helper_functions import (\n",
    "  process_csv_data,\n",
    "  add_seed_magnitude_column,\n",
    "  add_generator_iter_column,\n",
    "  add_seed_index_column\n",
    ")\n",
    "\n",
    "plt.set_cmap('viridis')\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "satzilla_features = process_csv_data(\"/home/csoare/experiments/reduced_instances_strategy2/features_output.csv\")\n",
    "\n",
    "satzilla_features = add_seed_magnitude_column(satzilla_features)\n",
    "satzilla_features = add_seed_index_column(satzilla_features)\n",
    "satzilla_features = add_generator_iter_column(satzilla_features)\n",
    "\n",
    "# Total instances\n",
    "total_instances = len(satzilla_features)\n",
    "\n",
    "# Average number of instances per generator\n",
    "avg_instances_per_generator = math.ceil(satzilla_features['generator'].value_counts().mean())\n",
    "\n",
    "# Number of unique seeds\n",
    "num_unique_seeds = len(satzilla_features['seed_magnitude'].unique())\n",
    "\n",
    "# Number of instances per generator per seed\n",
    "nr_of_instances_per_generator_per_seed = satzilla_features['generator_iter_number'].nunique()\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Total number of instances: {total_instances}\")\n",
    "print(f\"Average instances per generator: {avg_instances_per_generator}\")\n",
    "print(f\"Number of unique seeds: {num_unique_seeds}\")\n",
    "print(f\"Instances per generator per seed: {nr_of_instances_per_generator_per_seed}\")\n",
    "\n",
    "def find_missing_instances(cnf_dir: str, features_csv: str) -> list:\n",
    "    \"\"\"\n",
    "    Find CNF files that were not processed in the features CSV.\n",
    "    \n",
    "    Args:\n",
    "        cnf_dir (str): Directory containing the original CNF files\n",
    "        features_csv (str): Path to the features CSV file\n",
    "        \n",
    "    Returns:\n",
    "        list: Names of CNF files that were not processed\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Read all CNF filenames\n",
    "    cnf_files = set()\n",
    "    for cnf_file in Path(cnf_dir).glob(\"*.cnf\"):\n",
    "        cnf_files.add(cnf_file.stem)\n",
    "    \n",
    "    # Read processed instances from CSV\n",
    "    df = pd.read_csv(features_csv)\n",
    "    processed_instances = set(df['instance_name'])\n",
    "    \n",
    "    # Find missing instances\n",
    "    missing = cnf_files - processed_instances\n",
    "    \n",
    "    return sorted(list(missing))\n",
    "\n",
    "missing = find_missing_instances(\"/home/csoare/experiments/feature_analysis2/instances/cnf\", \"/home/csoare/experiments/feature_analysis2/feaures.csv\")\n",
    "if missing:\n",
    "    print(f\"Found {len(missing)} unprocessed instances:\")\n",
    "    for instance in missing:\n",
    "        print(f\"  - {instance}\")\n",
    "else:\n",
    "    print(\"All CNF files were processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_generator_properties(df):\n",
    "    \"\"\"\n",
    "    Extract base generator name, difficulty and randomness from generator column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'generator' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new 'base_generator', 'difficulty' and 'randomness' columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    split_values = df['generator'].str.split('-', expand=True)\n",
    "    df['base_generator'] = split_values[0]  # 'FuzzSAT' or 'PairSAT'\n",
    "    df['difficulty'] = split_values[1]  # 'easy', 'medium', 'hard'\n",
    "    df['randomness'] = split_values[2].astype(int)  # 0, 50, 100\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "satzilla_features = extract_generator_properties(satzilla_features)\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"\\nUnique difficulties:\", satzilla_features['difficulty'].unique())\n",
    "print(\"Unique randomness values:\", satzilla_features['randomness'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b8195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for all analyses\n",
    "def get_numeric_features(df):\n",
    "    \"\"\"Get numeric features, excluding metadata columns\"\"\"\n",
    "    features_to_exclude = ['seed', 'seed_magnitude', 'seed_index', 'randomness', \n",
    "                          'generator_iter_number', 'instance_name', 'solved']\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    return [col for col in numeric_cols if col not in features_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9578644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stats_dataframe(df):\n",
    "    \"\"\"\n",
    "    Create a DataFrame where each numeric feature is represented by a stats object.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with generator column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with stats objects for each numeric feature\n",
    "    \"\"\"\n",
    "    numeric_cols = get_numeric_features(df)\n",
    "    \n",
    "    # Initialize empty DataFrame with generator as index\n",
    "    stats_df = pd.DataFrame(index=df['generator'].unique())\n",
    "    \n",
    "    # For each numeric column, calculate stats and create dict\n",
    "    for col in numeric_cols:\n",
    "        grouped_stats = df.groupby('generator')[col].agg([\n",
    "            ('mean', 'mean'),\n",
    "            ('std', 'std'),\n",
    "            ('var', 'var'),\n",
    "            ('min', 'min'),\n",
    "            ('max', 'max'),\n",
    "            ('median', 'median')\n",
    "        ])\n",
    "        \n",
    "        # Convert stats to dictionary for each generator\n",
    "        stats_dict = {\n",
    "            idx: {\n",
    "                'mean': row['mean'],\n",
    "                'std': row['std'],\n",
    "                'var': row['var'],\n",
    "                'min': row['min'],\n",
    "                'max': row['max'],\n",
    "                'median': row['median']\n",
    "            }\n",
    "            for idx, row in grouped_stats.iterrows()\n",
    "        }\n",
    "            \n",
    "        stats_df[col] = pd.Series(stats_dict)\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# Create the stats DataFrame\n",
    "all_instances_stats_df = create_stats_dataframe(satzilla_features)\n",
    "\n",
    "# all_instances_stats_df.to_csv(\"/home/csoare/experiments/feature_analysis2/all_instances_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_generators(df):\n",
    "   \"\"\"\n",
    "   Find statistically similar generators across randomness and difficulty levels.\n",
    "   \n",
    "   This function performs t-tests on all numeric features to identify generators that produce\n",
    "   statistically similar distributions. It compares:\n",
    "   1. Different randomness levels within the same generator and difficulty\n",
    "   2. Different difficulty levels within the same generator and randomness\n",
    "   \n",
    "   Parameters:\n",
    "       df (pd.DataFrame): DataFrame containing generator data with columns:\n",
    "           - base_generator: The generator type\n",
    "           - difficulty: The difficulty level\n",
    "           - randomness: The randomness level\n",
    "           - Various numeric feature columns\n",
    "           \n",
    "   Returns:\n",
    "       tuple: (similar_pairs, filtered_df) where:\n",
    "           - similar_pairs: Dict mapping generator keys to lists of similar (r1,r2) or (d1,d2) pairs\n",
    "           - filtered_df: DataFrame with one of each similar pair removed\n",
    "   \"\"\"\n",
    "   results = {}\n",
    "   filtered_df = df.copy()\n",
    "   \n",
    "   for base in df['base_generator'].unique():\n",
    "       for diff in df['difficulty'].unique():\n",
    "           key = f\"{base}-{diff}\"\n",
    "           data = df[(df['base_generator'] == base) & (df['difficulty'] == diff)]\n",
    "           if len(data) == 0:\n",
    "               continue\n",
    "               \n",
    "           features = get_numeric_features(data)\n",
    "           rand_values = sorted(data['randomness'].unique())\n",
    "           \n",
    "           similar_pairs = []\n",
    "           for i in range(len(rand_values)):\n",
    "               for j in range(i + 1, len(rand_values)):\n",
    "                   r1, r2 = int(rand_values[i]), int(rand_values[j])  # Convert to int\n",
    "                   all_features_similar = True\n",
    "                   \n",
    "                   for feature in features:\n",
    "                       if data[feature].nunique() > 1:\n",
    "                           dist1 = data[data['randomness'] == r1][feature]\n",
    "                           dist2 = data[data['randomness'] == r2][feature]\n",
    "                           _, p_val = stats.ttest_ind(dist1, dist2)\n",
    "                           if p_val <= 0.05:\n",
    "                               all_features_similar = False\n",
    "                               break\n",
    "                               \n",
    "                   if all_features_similar:\n",
    "                       similar_pairs.append(('R', r1, r2))\n",
    "                       filtered_df = filtered_df[~((filtered_df['base_generator'] == base) & \n",
    "                                                 (filtered_df['difficulty'] == diff) & \n",
    "                                                 (filtered_df['randomness'] == r2))]\n",
    "           \n",
    "           if similar_pairs:\n",
    "               results[key] = similar_pairs\n",
    "   \n",
    "   for base in df['base_generator'].unique():\n",
    "       for rand in df['randomness'].unique():\n",
    "           key = f\"{base}-R{rand}\"\n",
    "           data = df[(df['base_generator'] == base) & (df['randomness'] == rand)]\n",
    "           if len(data) == 0:\n",
    "               continue\n",
    "               \n",
    "           features = get_numeric_features(data)\n",
    "           diff_values = sorted(data['difficulty'].unique())\n",
    "           \n",
    "           similar_pairs = []\n",
    "           for i in range(len(diff_values)):\n",
    "               for j in range(i + 1, len(diff_values)):\n",
    "                   d1, d2 = diff_values[i], diff_values[j]\n",
    "                   all_features_similar = True\n",
    "                   \n",
    "                   for feature in features:\n",
    "                       if data[feature].nunique() > 1:\n",
    "                           dist1 = data[data['difficulty'] == d1][feature]\n",
    "                           dist2 = data[data['difficulty'] == d2][feature]\n",
    "                           _, p_val = stats.ttest_ind(dist1, dist2)\n",
    "                           if p_val <= 0.05:\n",
    "                               all_features_similar = False\n",
    "                               break\n",
    "                               \n",
    "                   if all_features_similar:\n",
    "                       similar_pairs.append(('D', d1, d2))\n",
    "                       filtered_df = filtered_df[~((filtered_df['base_generator'] == base) & \n",
    "                                                 (filtered_df['difficulty'] == d2) & \n",
    "                                                 (filtered_df['randomness'] == rand))]\n",
    "           \n",
    "           if similar_pairs:\n",
    "               results[key] = similar_pairs\n",
    "               \n",
    "   return results, filtered_df\n",
    "\n",
    "similar_generators, filtered_satzilla_features = find_similar_generators(satzilla_features)\n",
    "print(similar_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_randomness_predictors(df, n=5):\n",
    "   features = get_numeric_features(df)\n",
    "   results = {}\n",
    "   difficulty_order = [\"easy\", \"medium\", \"hard\"]\n",
    "   \n",
    "   for base in df['base_generator'].unique():\n",
    "       for diff in difficulty_order:\n",
    "           key = f\"{base}-{diff}\"\n",
    "           data = df[(df['base_generator'] == base) & (df['difficulty'] == diff)]\n",
    "           if len(data) == 0:\n",
    "               continue\n",
    "               \n",
    "           correlations = {}\n",
    "           for feature in features:\n",
    "               if data[feature].nunique() > 1:\n",
    "                   corr = data[feature].corr(data['randomness'], method='spearman')\n",
    "                   if not np.isnan(corr):\n",
    "                       correlations[feature] = abs(corr)\n",
    "                       \n",
    "           if not correlations:\n",
    "               continue\n",
    "               \n",
    "           sorted_predictors = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "           top_predictors = sorted_predictors[:n]\n",
    "           bottom_predictors = sorted_predictors[-n:]\n",
    "           results[key] = {'top': top_predictors, 'bottom': bottom_predictors}\n",
    "           \n",
    "           fig, axes = plt.subplots(2, n, figsize=(4*n, 8))\n",
    "           \n",
    "           # Plot top predictors\n",
    "           for idx, (feature, corr) in enumerate(top_predictors):\n",
    "               rand_values = sorted(data['randomness'].unique())\n",
    "               for rand in rand_values:\n",
    "                   subset = data[data['randomness'] == rand][feature]\n",
    "                   try:\n",
    "                       density = gaussian_kde(subset)\n",
    "                       xs = np.linspace(subset.min(), subset.max(), 200)\n",
    "                       ys = density(xs)\n",
    "                       ys = ys / np.max(ys)\n",
    "                       axes[0, idx].plot(xs, ys, label=f'Randomness={rand}%')\n",
    "                       axes[0, idx].fill_between(xs, ys, alpha=0.2)\n",
    "                   except np.linalg.LinAlgError:\n",
    "                       axes[0, idx].hist(subset, bins=20, density=True, alpha=0.5, label=f'Randomness={rand}%')\n",
    "               axes[0, idx].set_title(f'{feature}\\ncorr={corr:.3f}')\n",
    "               axes[0, idx].legend()\n",
    "               axes[0, idx].set_xlabel(feature)\n",
    "               axes[0, idx].set_ylabel('Density')\n",
    "           \n",
    "           # Plot bottom predictors\n",
    "           for idx, (feature, corr) in enumerate(bottom_predictors):\n",
    "               rand_values = sorted(data['randomness'].unique())\n",
    "               for rand in rand_values:\n",
    "                   subset = data[data['randomness'] == rand][feature]\n",
    "                   try:\n",
    "                       density = gaussian_kde(subset)\n",
    "                       xs = np.linspace(subset.min(), subset.max(), 200)\n",
    "                       ys = density(xs)\n",
    "                       ys = ys / np.max(ys)\n",
    "                       axes[1, idx].plot(xs, ys, label=f'Randomness={rand}%')\n",
    "                       axes[1, idx].fill_between(xs, ys, alpha=0.2)\n",
    "                   except np.linalg.LinAlgError:\n",
    "                       axes[1, idx].hist(subset, bins=20, density=True, alpha=0.5, label=f'Randomness={rand}%')\n",
    "               axes[1, idx].set_title(f'{feature}\\ncorr={corr:.3f}')\n",
    "               axes[1, idx].legend()\n",
    "               axes[1, idx].set_xlabel(feature)\n",
    "               axes[1, idx].set_ylabel('Density')\n",
    "           \n",
    "           plt.suptitle(f'Top and Bottom Randomness Predictors for {key}')\n",
    "           plt.tight_layout()\n",
    "           plt.show()\n",
    "           \n",
    "   return results\n",
    "\n",
    "randomness_results = analyze_randomness_predictors(filtered_satzilla_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da208ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_difficulty_predictors(df, n=5):\n",
    "   \"\"\"\n",
    "   Analyzes and visualizes both top and bottom predictors of difficulty levels.\n",
    "   Parameters:\n",
    "       df (pd.DataFrame): Input DataFrame with generator data\n",
    "       n (int): Number of top/bottom predictors to show. Default is 5\n",
    "   Returns:\n",
    "       dict: Dictionary containing top/bottom predictor results\n",
    "   \"\"\"\n",
    "   features = get_numeric_features(df)\n",
    "   results = {}\n",
    "   difficulty_order = [\"easy\", \"medium\", \"hard\"]\n",
    "   \n",
    "   for base in df['base_generator'].unique():\n",
    "       for rand in sorted(df['randomness'].unique()):\n",
    "           key = f\"{base}-R{rand}\"\n",
    "           data = df[(df['base_generator'] == base) & (df['randomness'] == rand)].copy()\n",
    "           if len(data) == 0:\n",
    "               continue\n",
    "               \n",
    "           # Convert difficulty to numeric\n",
    "           diff_map = {'easy': 0, 'medium': 1, 'hard': 2}\n",
    "           data['diff_numeric'] = data['difficulty'].map(diff_map)\n",
    "           \n",
    "           correlations = {}\n",
    "           for feature in features:\n",
    "               if data[feature].nunique() > 1:\n",
    "                   corr = data[feature].corr(data['diff_numeric'], method='spearman')\n",
    "                   if not np.isnan(corr):\n",
    "                       correlations[feature] = abs(corr)\n",
    "                       \n",
    "           if not correlations:\n",
    "               continue\n",
    "               \n",
    "           sorted_predictors = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "           top_predictors = sorted_predictors[:n]\n",
    "           bottom_predictors = sorted_predictors[-n:]\n",
    "           results[key] = {'top': top_predictors, 'bottom': bottom_predictors}\n",
    "           \n",
    "           # Create two rows of subplots\n",
    "           fig, axes = plt.subplots(2, n, figsize=(4*n, 8))\n",
    "           \n",
    "           # Plot top predictors\n",
    "           for idx, (feature, corr) in enumerate(top_predictors):\n",
    "               for diff in difficulty_order:\n",
    "                   subset = data[data['difficulty'] == diff][feature]\n",
    "                   if subset.nunique() == 1:\n",
    "                       # If only one value, plot a vertical line\n",
    "                       value = subset.iloc[0]\n",
    "                       axes[0, idx].axvline(x=value, label=f'{diff} (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       try:\n",
    "                           if subset.nunique() > 3:\n",
    "                               density = gaussian_kde(subset)\n",
    "                               xs = np.linspace(subset.min(), subset.max(), 200)\n",
    "                               ys = density(xs)\n",
    "                               ys = ys / np.max(ys)\n",
    "                               axes[0, idx].plot(xs, ys, label=diff, linewidth=2)\n",
    "                               axes[0, idx].fill_between(xs, ys, alpha=0.2)\n",
    "                           else:\n",
    "                               axes[0, idx].violinplot(subset, positions=[['easy', 'medium', 'hard'].index(diff)])\n",
    "                               axes[0, idx].set_xticks([0, 1, 2], ['easy', 'medium', 'hard'])\n",
    "                       except Exception:\n",
    "                           sorted_vals = sorted(subset)\n",
    "                           axes[0, idx].plot(range(len(sorted_vals)), sorted_vals, label=diff, alpha=0.5, linewidth=2)\n",
    "               axes[0, idx].set_title(f'{feature}\\ncorr={corr:.3f}', fontsize=14, pad=10)\n",
    "               axes[0, idx].legend(fontsize=12)\n",
    "               axes[0, idx].set_xlabel(feature, fontsize=12, labelpad=8)\n",
    "               axes[0, idx].set_ylabel('Density/Value', fontsize=12, labelpad=8)\n",
    "               axes[0, idx].tick_params(axis='both', which='major', labelsize=10)\n",
    "           \n",
    "           # Plot bottom predictors (same changes as top)\n",
    "           for idx, (feature, corr) in enumerate(bottom_predictors):\n",
    "               for diff in difficulty_order:\n",
    "                   subset = data[data['difficulty'] == diff][feature]\n",
    "                   if subset.nunique() == 1:\n",
    "                       value = subset.iloc[0]\n",
    "                       axes[1, idx].axvline(x=value, label=f'{diff} (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       try:\n",
    "                           if subset.nunique() > 3:\n",
    "                               density = gaussian_kde(subset)\n",
    "                               xs = np.linspace(subset.min(), subset.max(), 200)\n",
    "                               ys = density(xs)\n",
    "                               ys = ys / np.max(ys)\n",
    "                               axes[1, idx].plot(xs, ys, label=diff, linewidth=2)\n",
    "                               axes[1, idx].fill_between(xs, ys, alpha=0.2)\n",
    "                           else:\n",
    "                               axes[1, idx].violinplot(subset, positions=[['easy', 'medium', 'hard'].index(diff)])\n",
    "                               axes[1, idx].set_xticks([0, 1, 2], ['easy', 'medium', 'hard'])\n",
    "                       except Exception:\n",
    "                           sorted_vals = sorted(subset)\n",
    "                           axes[1, idx].plot(range(len(sorted_vals)), sorted_vals, label=diff, alpha=0.5, linewidth=2)\n",
    "               axes[1, idx].set_title(f'{feature}\\ncorr={corr:.3f}', fontsize=14, pad=10)\n",
    "               axes[1, idx].legend(fontsize=12)\n",
    "               axes[1, idx].set_xlabel(feature, fontsize=12, labelpad=8)\n",
    "               axes[1, idx].set_ylabel('Density/Value', fontsize=12, labelpad=8)\n",
    "               axes[1, idx].tick_params(axis='both', which='major', labelsize=10)\n",
    "           \n",
    "           plt.suptitle(f'Top and Bottom Difficulty Predictors for {base} with Randomness: {rand}%', \n",
    "                       fontsize=16, y=1.05)\n",
    "           plt.tight_layout()\n",
    "           plt.show()\n",
    "           \n",
    "   return results\n",
    "\n",
    "difficulty_results = analyze_difficulty_predictors(filtered_satzilla_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_generators(df, n=5):\n",
    "   \"\"\"\n",
    "   Compare features between generator pairs for same difficulty and randomness levels.\n",
    "   Shows both top and bottom differentiating features using effect size.\n",
    "   \n",
    "   Parameters:\n",
    "       df (pd.DataFrame): Input DataFrame with generator data\n",
    "       n (int): Number of top/bottom features to compare. Default is 5\n",
    "       \n",
    "   Returns:\n",
    "       dict: Dictionary containing comparison results\n",
    "   \"\"\"\n",
    "   features = get_numeric_features(df)\n",
    "   results = {}\n",
    "   difficulty_order = [\"easy\", \"medium\", \"hard\"]\n",
    "   \n",
    "   plt.rcParams.update({'font.size': 12})\n",
    "   \n",
    "   for diff in difficulty_order:\n",
    "       for rand in sorted(df['randomness'].unique()):\n",
    "           key = f\"{diff}-R{rand}\"\n",
    "           data_fuzz = df[(df['base_generator'] == 'FuzzSAT') &\n",
    "                         (df['difficulty'] == diff) &\n",
    "                         (df['randomness'] == rand)]\n",
    "           data_pair = df[(df['base_generator'] == 'PairSAT') &\n",
    "                         (df['difficulty'] == diff) &\n",
    "                         (df['randomness'] == rand)]\n",
    "           \n",
    "           if len(data_fuzz) == 0 or len(data_pair) == 0:\n",
    "               continue\n",
    "               \n",
    "           # Calculate effect sizes for features with at least one non-constant group\n",
    "           effect_sizes = {}\n",
    "           for feature in features:\n",
    "               try:\n",
    "                   if data_fuzz[feature].nunique() > 1 or data_pair[feature].nunique() > 1:\n",
    "                       d = (data_fuzz[feature].mean() - data_pair[feature].mean()) / \\\n",
    "                           np.sqrt((data_fuzz[feature].var() + data_pair[feature].var()) / 2)\n",
    "                       if not np.isnan(d):\n",
    "                           effect_sizes[feature] = abs(d)\n",
    "               except Exception:\n",
    "                   continue\n",
    "                   \n",
    "           if not effect_sizes:\n",
    "               continue\n",
    "               \n",
    "           sorted_effects = sorted(effect_sizes.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "           top_diff = sorted_effects[:n]\n",
    "           bottom_diff = sorted_effects[-n:]\n",
    "           results[key] = {'top': top_diff, 'bottom': bottom_diff}\n",
    "           \n",
    "           # Create two rows of subplots\n",
    "           fig, axes = plt.subplots(2, n, figsize=(4*n, 8))\n",
    "           \n",
    "           # Plot top differences\n",
    "           for idx, (feature, effect) in enumerate(top_diff):\n",
    "               try:\n",
    "                   # Handle FuzzSAT distribution/constant\n",
    "                   if data_fuzz[feature].nunique() == 1:\n",
    "                       value = data_fuzz[feature].iloc[0]\n",
    "                       axes[0, idx].axvline(x=value, color='blue', \n",
    "                                          label=f'FuzzSAT (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       density_fuzz = gaussian_kde(data_fuzz[feature])\n",
    "                       xs_fuzz = np.linspace(data_fuzz[feature].min(), data_fuzz[feature].max(), 200)\n",
    "                       ys_fuzz = density_fuzz(xs_fuzz)\n",
    "                       ys_fuzz = ys_fuzz / np.max(ys_fuzz)\n",
    "                       axes[0, idx].plot(xs_fuzz, ys_fuzz, label='FuzzSAT', linewidth=2)\n",
    "                       axes[0, idx].fill_between(xs_fuzz, ys_fuzz, alpha=0.2)\n",
    "                       \n",
    "                   # Handle PairSAT distribution/constant\n",
    "                   if data_pair[feature].nunique() == 1:\n",
    "                       value = data_pair[feature].iloc[0]\n",
    "                       axes[0, idx].axvline(x=value, color='orange',\n",
    "                                          label=f'PairSAT (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       density_pair = gaussian_kde(data_pair[feature])\n",
    "                       xs_pair = np.linspace(data_pair[feature].min(), data_pair[feature].max(), 200)\n",
    "                       ys_pair = density_pair(xs_pair)\n",
    "                       ys_pair = ys_pair / np.max(ys_pair)\n",
    "                       axes[0, idx].plot(xs_pair, ys_pair, label='PairSAT', linewidth=2)\n",
    "                       axes[0, idx].fill_between(xs_pair, ys_pair, alpha=0.2)\n",
    "               except Exception:\n",
    "                   data_to_plot = [data_fuzz[feature], data_pair[feature]]\n",
    "                   axes[0, idx].boxplot(data_to_plot, labels=['FuzzSAT', 'PairSAT'])\n",
    "               \n",
    "               axes[0, idx].set_title(f'{feature}\\nEffect Size={effect:.3f}', fontsize=14, pad=10)\n",
    "               axes[0, idx].legend(fontsize=12)\n",
    "               axes[0, idx].set_xlabel(feature, fontsize=12, labelpad=8)\n",
    "               axes[0, idx].set_ylabel('Density', fontsize=12, labelpad=8)\n",
    "               axes[0, idx].tick_params(axis='both', which='major', labelsize=10)\n",
    "           \n",
    "           # Plot bottom differences (same logic as top)\n",
    "           for idx, (feature, effect) in enumerate(bottom_diff):\n",
    "               try:\n",
    "                   # Handle FuzzSAT distribution/constant\n",
    "                   if data_fuzz[feature].nunique() == 1:\n",
    "                       value = data_fuzz[feature].iloc[0]\n",
    "                       axes[1, idx].axvline(x=value, color='blue',\n",
    "                                          label=f'FuzzSAT (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       density_fuzz = gaussian_kde(data_fuzz[feature])\n",
    "                       xs_fuzz = np.linspace(data_fuzz[feature].min(), data_fuzz[feature].max(), 200)\n",
    "                       ys_fuzz = density_fuzz(xs_fuzz)\n",
    "                       ys_fuzz = ys_fuzz / np.max(ys_fuzz)\n",
    "                       axes[1, idx].plot(xs_fuzz, ys_fuzz, label='FuzzSAT', linewidth=2)\n",
    "                       axes[1, idx].fill_between(xs_fuzz, ys_fuzz, alpha=0.2)\n",
    "                       \n",
    "                   # Handle PairSAT distribution/constant\n",
    "                   if data_pair[feature].nunique() == 1:\n",
    "                       value = data_pair[feature].iloc[0]\n",
    "                       axes[1, idx].axvline(x=value, color='orange',\n",
    "                                          label=f'PairSAT (constant={value:.2f})', \n",
    "                                          linestyle='--', alpha=0.8)\n",
    "                   else:\n",
    "                       density_pair = gaussian_kde(data_pair[feature])\n",
    "                       xs_pair = np.linspace(data_pair[feature].min(), data_pair[feature].max(), 200)\n",
    "                       ys_pair = density_pair(xs_pair)\n",
    "                       ys_pair = ys_pair / np.max(ys_pair)\n",
    "                       axes[1, idx].plot(xs_pair, ys_pair, label='PairSAT', linewidth=2)\n",
    "                       axes[1, idx].fill_between(xs_pair, ys_pair, alpha=0.2)\n",
    "               except Exception:\n",
    "                   data_to_plot = [data_fuzz[feature], data_pair[feature]]\n",
    "                   axes[1, idx].boxplot(data_to_plot, labels=['FuzzSAT', 'PairSAT'])\n",
    "                   \n",
    "               axes[1, idx].set_title(f'{feature}\\nEffect Size={effect:.3f}', fontsize=14, pad=10)\n",
    "               axes[1, idx].legend(fontsize=12)\n",
    "               axes[1, idx].set_xlabel(feature, fontsize=12, labelpad=8)\n",
    "               axes[1, idx].set_ylabel('Density', fontsize=12, labelpad=8)\n",
    "               axes[1, idx].tick_params(axis='both', which='major', labelsize=10)\n",
    "           \n",
    "           plt.suptitle(f'Top and Bottom Differentiating Features for Difficulty: {diff}, Randomness: {rand}%', \n",
    "                       fontsize=16, y=1.05)\n",
    "           plt.tight_layout()\n",
    "           plt.show()\n",
    "           \n",
    "   return results\n",
    "\n",
    "generator_results = compare_generators(satzilla_features, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
